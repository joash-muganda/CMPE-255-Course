# Clustering of Documents Using LLM Embeddings

This repository contains the code and resources for the project on clustering constitutional documents using embeddings generated from Large Language Models (LLMs). The project aims to explore semantic similarities among different constitutional texts by leveraging state-of-the-art natural language processing techniques.

## Objective

The primary objective of this project is to cluster constitutional documents from various countries using embeddings generated by LLMs, providing insights into the semantic similarities between these documents.

## Methodology

The project follows these key steps:

1. **Extract Embeddings**: Generate embeddings for each constitutional document using an LLM.
2. **Clustering**: Apply a clustering algorithm, specifically K-Means, to these embeddings.
3. **Analysis**: Analyze the formed clusters in terms of document similarity.

Two different LLM approaches were utilized for this project:

- Sentence Transformers
- BERT (Bidirectional Encoder Representations from Transformers)

## Repository Structure

- `code/`: Contains all the Python scripts used for generating embeddings, clustering, and analysis.
- `data/`: Contains the constitutional documents in text format.
- `results/`: Includes the clustering results and any generated plots or analysis summaries.

## Key Findings

- Different LLMs can lead to varying clustering outcomes, influenced by their specific design and training.
- The BERT model provided more nuanced clustering, potentially more suitable for detailed legal analysis.
- Sentence transformers tended to group documents based on broader themes.

For a detailed account of the project's methodology, results, and analysis, please refer to the [Documentation](#).

## Usage

Instructions for setting up the environment, running the scripts, and replicating the analysis are provided in the `code/` directory.

## Contributing

Contributions to this project are welcome. Please refer to `CONTRIBUTING.md` for guidelines.

## License

This project is licensed under the MIT License - see the `LICENSE.md` file for details.

## Contact

For any queries or further discussions related to this project, please contact [Your Contact Information].

## Acknowledgements

- Thanks to all the contributors and maintainers of the LLMs and Python libraries used in this project.
- Special thanks to [Any Collaborators or Institutions] for their support and contributions.
